{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mMgW-c7V50o9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "import scipy.optimize as optimization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "NUM_TRADING_DAYS = 252\n",
        "DEFAULT_RISK_FREE = 0.015\n",
        "RANDOM_SEED = 42\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def _extract_prices(raw):\n",
        "    if isinstance(raw.columns, pd.MultiIndex):\n",
        "        for primary in ('Close', 'Adj Close', 'AdjClose', 'close', 'adjclose'):\n",
        "            if primary in raw.columns.get_level_values(0):\n",
        "                return raw[primary]\n",
        "        tickers = list(raw.columns.levels[0])\n",
        "        frames = {}\n",
        "        for t in tickers:\n",
        "            subcols = [c for c in raw.columns if c[0] == t]\n",
        "            if subcols:\n",
        "                frames[t] = raw[subcols[0]]\n",
        "        return pd.DataFrame(frames)\n",
        "    return raw\n",
        "\n",
        "\n",
        "def download_prices(tickers, start, end=None, auto_adjust=True, progress=False):\n",
        "    end = end or datetime.today().strftime('%Y-%m-%d')\n",
        "    raw = yf.download(tickers, start=start, end=end, auto_adjust=auto_adjust, progress=progress)\n",
        "    if raw is None or raw.empty:\n",
        "        raise RuntimeError(\"yfinance returned no data. Check tickers/date range/Internet.\")\n",
        "    prices = _extract_prices(raw)\n",
        "    if isinstance(prices, pd.Series):\n",
        "        prices = prices.to_frame(name=(tickers[0] if isinstance(tickers, (list, tuple)) else str(tickers)))\n",
        "    return prices.dropna(axis=1, how='all')\n"
      ],
      "metadata": {
        "id": "1B6MkBU4sEcw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def simple_to_annual_metrics(daily_simple):\n",
        "    if daily_simple.empty:\n",
        "        return np.nan, np.nan\n",
        "    cumulative = (1 + daily_simple).prod() - 1\n",
        "    days = daily_simple.shape[0]\n",
        "    cagr = (1 + cumulative) ** (NUM_TRADING_DAYS / days) - 1\n",
        "    ann_vol = daily_simple.std() * np.sqrt(NUM_TRADING_DAYS)\n",
        "    return cagr, ann_vol\n",
        "\n",
        "\n",
        "def sharpe_ratio(daily_simple, rf=DEFAULT_RISK_FREE):\n",
        "    cagr, vol = simple_to_annual_metrics(daily_simple)\n",
        "    if vol == 0 or np.isnan(vol):\n",
        "        return np.nan\n",
        "    return (cagr - rf) / vol\n",
        "\n",
        "\n",
        "def sortino_ratio(daily_simple, rf=DEFAULT_RISK_FREE):\n",
        "    if daily_simple.empty:\n",
        "        return np.nan\n",
        "    downside = daily_simple[daily_simple < 0]\n",
        "    if downside.empty:\n",
        "        return np.nan\n",
        "    cagr, _ = simple_to_annual_metrics(daily_simple)\n",
        "    dd = downside.std() * np.sqrt(NUM_TRADING_DAYS)\n",
        "    if dd == 0:\n",
        "        return np.nan\n",
        "    return (cagr - rf) / dd\n",
        "\n",
        "\n",
        "def max_drawdown(daily_simple):\n",
        "    if daily_simple.empty:\n",
        "        return np.nan\n",
        "    cum = (1 + daily_simple).cumprod()\n",
        "    peak = cum.cummax()\n",
        "    drawdown = (cum - peak) / peak\n",
        "    return drawdown.min()\n",
        "\n",
        "\n",
        "def historical_var(daily_simple, alpha=0.95):\n",
        "    if daily_simple.empty:\n",
        "        return np.nan\n",
        "    return -np.percentile(daily_simple, 100 * (1 - alpha))\n",
        "\n",
        "\n",
        "def historical_cvar(daily_simple, alpha=0.95):\n",
        "    if daily_simple.empty:\n",
        "        return np.nan\n",
        "    cutoff = np.percentile(daily_simple, 100 * (1 - alpha))\n",
        "    tail = daily_simple[daily_simple <= cutoff]\n",
        "    if tail.empty:\n",
        "        return 0.0\n",
        "    return -tail.mean()\n"
      ],
      "metadata": {
        "id": "PW91MPAUsHG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def simulate_random_portfolios(returns_log_df, num_portfolios=10000, rf=DEFAULT_RISK_FREE, seed=RANDOM_SEED):\n",
        "    np.random.seed(seed)\n",
        "    n = returns_log_df.shape[1]\n",
        "    mean_daily = returns_log_df.mean()\n",
        "    cov_annual = returns_log_df.cov() * NUM_TRADING_DAYS\n",
        "\n",
        "    rows = []\n",
        "    for _ in range(int(num_portfolios)):\n",
        "        w = np.random.random(n)\n",
        "        w /= w.sum()\n",
        "        ann_return = float(np.sum(mean_daily * w) * NUM_TRADING_DAYS)\n",
        "        ann_vol = float(np.sqrt(np.dot(w.T, cov_annual.dot(w))))\n",
        "        sharpe = (ann_return - rf) / ann_vol if ann_vol != 0 else 0.0\n",
        "        rows.append((ann_return, ann_vol, sharpe, w))\n",
        "    return pd.DataFrame(rows, columns=['Return', 'Volatility', 'Sharpe', 'Weights'])\n",
        "\n",
        "\n",
        "def optimize_max_sharpe(returns_log_df, rf=DEFAULT_RISK_FREE):\n",
        "    def neg_sharpe(weights, returns_df):\n",
        "        mean_daily = returns_df.mean()\n",
        "        cov_annual = returns_df.cov() * NUM_TRADING_DAYS\n",
        "        ann_return = np.sum(mean_daily * weights) * NUM_TRADING_DAYS\n",
        "        ann_vol = np.sqrt(np.dot(weights.T, cov_annual.dot(weights)))\n",
        "        if ann_vol == 0:\n",
        "            return 1e6\n",
        "        return -((ann_return - rf) / ann_vol)\n",
        "\n",
        "    n = returns_log_df.shape[1]\n",
        "    bounds = tuple((0.0, 1.0) for _ in range(n))\n",
        "    cons = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1},)\n",
        "    init = np.ones(n) / n\n",
        "    res = optimization.minimize(neg_sharpe, init, args=(returns_log_df,), method='SLSQP',\n",
        "                                bounds=bounds, constraints=cons,\n",
        "                                options={'maxiter': 1000, 'ftol': 1e-9})\n",
        "    return res\n"
      ],
      "metadata": {
        "id": "L1J6fQfzsLfp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prices_logreturns(prices_df):\n",
        "    return np.log(prices_df / prices_df.shift(1)).dropna()\n"
      ],
      "metadata": {
        "id": "gRmE_cFDsP7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def backtest_portfolio_with_rebalancing(prices_df, target_weights, rebalance_frequency='M', transaction_cost=0.0, verbose=False):\n",
        "    logrets = np.log(prices_df / prices_df.shift(1)).dropna()\n",
        "    simple_rets = np.expm1(logrets)\n",
        "\n",
        "    dates = simple_rets.index\n",
        "    tickers = prices_df.columns.tolist()\n",
        "    current_weights = np.array(target_weights, dtype=float)\n",
        "    current_weights /= current_weights.sum()\n",
        "\n",
        "    capital = 1.0\n",
        "    daily_port = []\n",
        "    date_list = []\n",
        "\n",
        "    if rebalance_frequency is None or rebalance_frequency == 'None':\n",
        "        rebal_dates = {dates[0]}\n",
        "    elif rebalance_frequency == 'M':\n",
        "        rebal_dates = set(pd.Series(dates).groupby(pd.Series(dates).dt.to_period('M')).first().values)\n",
        "    elif rebalance_frequency == 'Q':\n",
        "        rebal_dates = set(pd.Series(dates).groupby(pd.Series(dates).dt.to_period('Q')).first().values)\n",
        "    else:\n",
        "        rebal_dates = set(pd.Series(dates).groupby(pd.Series(dates).dt.to_period('M')).first().values)\n",
        "\n",
        "    prev_weights = current_weights.copy()\n",
        "    cumulative_turnover = 0.0\n",
        "\n",
        "    for dt in dates:\n",
        "        if dt in rebal_dates:\n",
        "            target = np.array(target_weights, dtype=float)\n",
        "            target /= target.sum()\n",
        "            turnover = np.sum(np.abs(target - prev_weights)) / 2.0\n",
        "            cost = capital * transaction_cost * turnover\n",
        "            capital -= cost\n",
        "            cumulative_turnover += turnover\n",
        "            prev_weights = target.copy()\n",
        "            current_weights = target.copy()\n",
        "            if verbose:\n",
        "                print(f\"{dt.date()} rebalance: turnover={turnover:.4f} cost={cost:.6f} capital={capital:.4f}\")\n",
        "\n",
        "        todays_rets = simple_rets.loc[dt].values\n",
        "        port_ret = float(np.dot(current_weights, todays_rets))\n",
        "        capital *= (1 + port_ret)\n",
        "        daily_port.append(port_ret)\n",
        "        date_list.append(dt)\n",
        "\n",
        "        denom = np.sum(current_weights * (1 + todays_rets))\n",
        "        new_weights = current_weights if denom == 0 else (current_weights * (1 + todays_rets)) / denom\n",
        "        prev_weights = new_weights.copy()\n",
        "        current_weights = new_weights.copy()\n",
        "\n",
        "    port_series = pd.Series(daily_port, index=date_list).sort_index()\n",
        "    details = {\n",
        "        'final_capital': capital,\n",
        "        'cumulative_turnover': cumulative_turnover,\n",
        "        'transaction_cost_rate': transaction_cost,\n",
        "        'rebalance_frequency': rebalance_frequency\n",
        "    }\n",
        "    return port_series, details\n"
      ],
      "metadata": {
        "id": "PJXXe0ThsSQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_pipeline(tickers,\n",
        "                 start_date='2015-01-01',\n",
        "                 end_date=None,\n",
        "                 num_portfolios=8000,\n",
        "                 risk_free=DEFAULT_RISK_FREE,\n",
        "                 rebalance_frequency='M',\n",
        "                 transaction_cost=0.0005,\n",
        "                 csv_out='optimal_weights.csv'):\n",
        "\n",
        "    prices = download_prices(tickers, start=start_date, end=end_date, auto_adjust=True, progress=False)\n",
        "    logrets = prices_logreturns(prices)\n",
        "\n",
        "    portfolios_df = simulate_random_portfolios(logrets, num_portfolios=num_portfolios, rf=risk_free, seed=RANDOM_SEED)\n",
        "\n",
        "    opt_res = optimize_max_sharpe(logrets, risk_free)\n",
        "    if not opt_res.success:\n",
        "        best_idx = portfolios_df['Sharpe'].idxmax()\n",
        "        opt_weights = portfolios_df.loc[best_idx, 'Weights']\n",
        "    else:\n",
        "        opt_weights = np.array(opt_res.x, dtype=float)\n",
        "\n",
        "    opt_weights = opt_weights if np.sum(opt_weights) != 0 else np.ones(len(prices.columns)) / len(prices.columns)\n",
        "    opt_weights = opt_weights / np.sum(opt_weights)\n",
        "\n",
        "    df_weights = pd.DataFrame({'Ticker': prices.columns, 'Weight': np.round(opt_weights, 6)})\n",
        "    df_weights.to_csv(csv_out, index=False)\n",
        "\n",
        "    port_daily, details = backtest_portfolio_with_rebalancing(prices, opt_weights,\n",
        "                                                              rebalance_frequency=rebalance_frequency,\n",
        "                                                              transaction_cost=transaction_cost,\n",
        "                                                              verbose=False)\n",
        "\n",
        "    bench = download_prices(['^GSPC'], start=start_date, end=end_date, auto_adjust=True, progress=False)\n",
        "    bench_series = bench.iloc[:, 0] if isinstance(bench, pd.DataFrame) else bench\n",
        "    bench_log = np.log(bench_series / bench_series.shift(1)).dropna()\n",
        "    bench_simple = np.expm1(bench_log)\n",
        "    bench_simple = bench_simple.reindex(port_daily.index).dropna()\n",
        "\n",
        "    port_summary = {\n",
        "        'Name': 'Optimal Portfolio',\n",
        "        'CAGR': simple_to_annual_metrics(port_daily)[0],\n",
        "        'Annual Vol': simple_to_annual_metrics(port_daily)[1],\n",
        "        'Sharpe': sharpe_ratio(port_daily, risk_free),\n",
        "        'Sortino': sortino_ratio(port_daily, risk_free),\n",
        "        'Max Drawdown': max_drawdown(port_daily),\n",
        "        'VaR(95%)': historical_var(port_daily, 0.95),\n",
        "        'CVaR(95%)': historical_cvar(port_daily, 0.95)\n",
        "    }\n",
        "    bench_summary = {\n",
        "        'Name': 'S&P 500 (Benchmark)',\n",
        "        'CAGR': simple_to_annual_metrics(bench_simple)[0],\n",
        "        'Annual Vol': simple_to_annual_metrics(bench_simple)[1],\n",
        "        'Sharpe': sharpe_ratio(bench_simple, risk_free),\n",
        "        'Sortino': sortino_ratio(bench_simple, risk_free),\n",
        "        'Max Drawdown': max_drawdown(bench_simple),\n",
        "        'VaR(95%)': historical_var(bench_simple, 0.95),\n",
        "        'CVaR(95%)': historical_cvar(bench_simple, 0.95)\n",
        "    }\n",
        "\n",
        "    return {\n",
        "        'weights_df': df_weights,\n",
        "        'port_summary': port_summary,\n",
        "        'bench_summary': bench_summary,\n",
        "        'csv': os.path.abspath(csv_out),\n",
        "        'backtest_details': details\n",
        "    }\n",
        "\n"
      ],
      "metadata": {
        "id": "VmMXM_yusU3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    TICKERS = ['MSFT', 'KO', 'TSLA', 'NFLX', 'JNJ']\n",
        "    START = '2015-01-01'\n",
        "    RESULT = run_pipeline(TICKERS,\n",
        "                          start_date=START,\n",
        "                          end_date=None,\n",
        "                          num_portfolios=8000,\n",
        "                          risk_free=0.015,\n",
        "                          rebalance_frequency='M',\n",
        "                          transaction_cost=0.0005,\n",
        "                          csv_out='optimal_weights.csv')\n",
        "\n",
        "    print(\"\\nOptimal weights (CSV):\")\n",
        "    print(RESULT['weights_df'].to_string(index=False))\n",
        "    print(\"\\nPortfolio summary:\")\n",
        "    for k, v in RESULT['port_summary'].items():\n",
        "        if k == 'Name': continue\n",
        "        print(f\"{k}: {v}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5CcvQV7sWBS",
        "outputId": "f8a59dbc-c562-4a09-ef56-f113dad5c68a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Optimal weights (CSV):\n",
            "Ticker   Weight\n",
            "   JNJ 0.053528\n",
            "    KO 0.084580\n",
            "  MSFT 0.607545\n",
            "  NFLX 0.200761\n",
            "  TSLA 0.053587\n",
            "\n",
            "Portfolio summary:\n",
            "CAGR: 0.2866754424499003\n",
            "Annual Vol: 0.27081446694306704\n",
            "Sharpe: 1.0031792079520414\n",
            "Sortino: 1.3691635877619817\n",
            "Max Drawdown: -0.4442300991400761\n",
            "VaR(95%): 0.027537683034723592\n",
            "CVaR(95%): 0.03951766070113495\n"
          ]
        }
      ]
    }
  ]
}